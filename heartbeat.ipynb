{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Patient = \"P005\" #\"P015/P015_S01_D2024-07-06\"\n",
    "run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import analyzer\n",
    "importlib.reload(analyzer)\n",
    "from analyzer import Analyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def load_patient_data(patient: str, run: str = None):\n",
    "    \"\"\"\n",
    "    Load patient data from the specified file.\n",
    "    \"\"\"\n",
    "\n",
    "    overview = pd.read_excel(\"Data/overview.xlsx\")\n",
    "    dir = \"Data/\" + patient + \"/\"\n",
    "    number = re.findall(r'\\d+', dir)\n",
    "    patient_number = int(number[0]) if number else None\n",
    "\n",
    "\n",
    "    if overview.loc[overview[\"Probanten Nr.\"] == patient_number, \"runs\"].values[0].strip() == \"-\":\n",
    "        print(f\"No runs found for patient {patient_number}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    add_filename, file_name = None, None\n",
    "    \n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith(\".tdms\") and file.startswith(patient):\n",
    "            if run and run not in file:\n",
    "                continue\n",
    "            if \"addCh\" in file:\n",
    "                add_filename = os.path.join(dir, file)\n",
    "            else:\n",
    "                file_name = os.path.join(dir, file)\n",
    "            \n",
    "    \n",
    "    log_file_path = os.path.join(dir, \"QZFM_log_file.txt\")\n",
    "    sensor_channels_to_exclude = json.loads(overview.loc[overview[\"Probanten Nr.\"] == patient_number, \"Sensors to exclude\"].values[0])\n",
    "\n",
    "    \n",
    "    try:\n",
    "        intervall = overview.loc[overview[\"Probanten Nr.\"] == patient_number, \"Intervall\"].values[0]\n",
    "        intervall = intervall.split(\":\") if isinstance(intervall, str) else intervall\n",
    "        intervall_start = int(intervall[0]) if isinstance(intervall, list) else None\n",
    "        intervall_end = int(intervall[1]) if isinstance(intervall, list) else None\n",
    "        print(f\"Intervall: {intervall_start} - {intervall_end}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing interval: {e}\")\n",
    "        intervall_start, intervall_end = None, None\n",
    "\n",
    "    try:\n",
    "        ica_filter = overview.loc[overview[\"Probanten Nr.\"] == patient_number, \"ICA Filter (x, y, z)\"].values[0].split(\";\")\n",
    "        print(f\"ICA Filter: {ica_filter}\")\n",
    "        ica_filter = [float(i) for i in ica_filter] if isinstance(ica_filter, list) else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing ICA filter: {e}\")\n",
    "        ica_filter = None\n",
    "\n",
    "\n",
    "    return Analyzer(\n",
    "        filename=file_name,\n",
    "        add_filename=add_filename,\n",
    "        log_file_path=log_file_path,\n",
    "        sensor_channels_to_exclude=sensor_channels_to_exclude\n",
    "    ), intervall_start, intervall_end, ica_filter\n",
    "\n",
    "analysis, intervall_start, intervall_end, ica_filter = load_patient_data(Patient, run)\n",
    "\n",
    "for k in analysis.key_list:\n",
    "    if k in [\"Brustlage\", \"Brust\", \"Bauchlage\", \"Bauch\"]:\n",
    "        key = k\n",
    "        break\n",
    "    \n",
    "(x_data, y_data, z_data), time, single_run = analysis.prepare_data(key, apply_default_filter=True, plot_alignment=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply ICA filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_data_intervall = x_data[:, :, intervall_start:intervall_end]\n",
    "y_data_intervall = y_data[:, :, intervall_start:intervall_end]\n",
    "z_data_intervall = z_data[:, :, intervall_start:intervall_end]\n",
    "time_intervall = time[intervall_start:intervall_end]\n",
    "single_run_intervall = single_run[:, intervall_start:intervall_end]\n",
    "\n",
    "\n",
    "#analysis.plot4x4(z_data[:, :, 250:1250], time[250:1250], name=\"z_data\")\n",
    "\n",
    "x_data_filtered, _, _, _ = analysis.ICA_filter(x_data_intervall, heart_beat_score_threshold=ica_filter[0], print_result=True)\n",
    "y_data_filtered, ica_components, _, _ = analysis.ICA_filter(y_data_intervall, heart_beat_score_threshold=ica_filter[1], plot_result=True)\n",
    "z_data_filtered, _, _, _ = analysis.ICA_filter(z_data_intervall, heart_beat_score_threshold=ica_filter[2])\n",
    "\n",
    "#print(ica_components.shape)\n",
    "#analysis.plot_sensor_matrix(ica_components[:, :500].reshape(4, 4, -1), time_intervall[:500], name=\"ica_components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_run_filtered = single_run_intervall#analysis.invert_field_directions(x_data_filtered, y_data_filtered, z_data_filtered, key, 48)\n",
    "\n",
    "\n",
    "analysis.butterfly_plot(single_run_filtered, time_intervall, 48, f\"Original {key}\")\n",
    "\n",
    "\n",
    "analysis.find_cleanest_channel(single_run_filtered)\n",
    "\n",
    "# use cleanest channel for peak detection\n",
    "peak_positions, ch, labels, _, _ = analysis.detect_qrs_complex_peaks_cleanest_channel(single_run_filtered, print_heart_rate=True, confidence_threshold=0.7, confidence_weight=1, plausibility_weight=0)\n",
    "if peak_positions is not None and len(peak_positions) > 0:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(single_run_filtered[ch, :], label='Signal', linewidth=1.2)\n",
    "    #plt.plot(resampled_data[ch, :], label='Signal', linewidth=1.2)\n",
    "    plt.plot(peak_positions, single_run_filtered[ch, peak_positions], \"ro\", markersize=6, label='R Peaks')\n",
    "    plt.title(f\"QRS Detection - Cleanest Channel {ch + 1}\")\n",
    "    plt.xlabel(\"Time (samples)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No R peaks detected or `peak_positions` is empty.\")\n",
    "analysis.plot_segmented_signal(single_run_filtered[ch, :], labels[ch, :])\n",
    "\n",
    "\n",
    "# window averaging\n",
    "avg_channels, time_window = analysis.avg_window(single_run_filtered, peak_positions, window_left=0.3, window_right=0.5)\n",
    "analysis.butterfly_plot(avg_channels, time_window, 48, f\"Original {key}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magentic Heart Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_channels = np.array(avg_channels)\n",
    "# --- Load averaged field data ---\n",
    "x_data_window, y_data_window, z_data_window = analysis.get_field_directions(avg_channels, key)\n",
    "\n",
    "analysis.plot_sensor_matrix(x_data_window, time_window, name=\"X-Field\")\n",
    "analysis.plot_sensor_matrix(y_data_window, time_window, name=\"Y-Field\")\n",
    "analysis.plot_sensor_matrix(z_data_window, time_window, name=\"Z-Field\")\n",
    "\n",
    "# Use a sample vector for projection\n",
    "f1_data = np.array([x_data_window[1, 0, :], y_data_window[1, 0, :]])\n",
    "print(f\"f1_data shape: {f1_data.shape}\")\n",
    "\n",
    "# --- Find cleanest channel ---\n",
    "best_channel, labels, confidence, _ = analysis.find_cleanest_channel(\n",
    "    avg_channels, confidence_weight=0.7, plausibility_weight=0.3\n",
    ")\n",
    "\n",
    "analysis.plot_segmented_signal(avg_channels[best_channel], labels[best_channel])\n",
    "\n",
    "print(\"#\" * 90)\n",
    "print(\"T-Wave Segment Extraction\")\n",
    "print(\"#\" * 90)\n",
    "\n",
    "# --- Extract T-wave segment ---\n",
    "mask_t = labels[best_channel] == 3\n",
    "mask_t[:110] = False  # Ignore early segment\n",
    "mask_t[175:] = False  # Ignore late segment\n",
    "\n",
    "t_segment = None\n",
    "if np.any(mask_t): \n",
    "    t_indices = np.where(mask_t)[0]\n",
    "    t_start, t_end = t_indices[0] + 10, t_indices[-1] + 10\n",
    "    t_segment = f1_data[:, t_start:t_end]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t_segment[0], label='X')\n",
    "    plt.plot(t_segment[1], label='Y')\n",
    "    plt.legend()\n",
    "    plt.title(\"T Segment (after index 75)\")\n",
    "    plt.show()\n",
    "\n",
    "    analysis.plot_heart_vector_projection(t_segment[0], t_segment[1], \"xy-Projection\", \"T Segment\")\n",
    "else:\n",
    "    print(\"No T-wave segment found!\")\n",
    "\n",
    "print(\"#\" * 90)\n",
    "print(\"QRS to T-Peak Segment with Lorentzian Fit\")\n",
    "print(\"#\" * 90)\n",
    "\n",
    "# --- Segment from end of QRS to T-peak ---\n",
    "mask_qrs = labels[best_channel] == 2\n",
    "mask_qrs[:50] = False\n",
    "mask_qrs[-50:] = False\n",
    "\n",
    "if np.any(mask_qrs) and t_segment is not None:\n",
    "    t_start_qrs = np.where(mask_qrs)[0][0] \n",
    "    t_end_qrs = np.where(mask_qrs)[0][-1] \n",
    "    # QRS  segment\n",
    "    segment_qrs = f1_data[:, t_start_qrs:t_end_qrs]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(segment_qrs[0])\n",
    "    plt.plot(segment_qrs[1])\n",
    "    plt.title(\"QRS Segment\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    analysis.plot_heart_vector_projection(\n",
    "        segment_qrs[0], segment_qrs[1],\n",
    "        \"xy-Projection\", \"QRS Segment\"\n",
    "    )\n",
    "else:\n",
    "    print(\"QRS or T segment not found!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICD Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = \"P019\" #\"P015/P015_S01_D2024-07-06\"\n",
    "date = \"2024-08-29\"\n",
    "run = \"S01\"\n",
    "\n",
    "log_file_path = f\"Data/{patient}/QZFM_log_file.txt\"\n",
    "add_filename = f\"Data/{patient}/{patient}_{run}_D{date}_addCh.tdms\"\n",
    "file_name = f\"Data/{patient}/{patient}_{run}_D{date}.tdms\"\n",
    "\n",
    "analysis = Analyzer(\n",
    "    \n",
    "        filename=file_name,\n",
    "        add_filename=add_filename,\n",
    "        log_file_path=log_file_path,\n",
    "        sensor_channels_to_exclude={}\n",
    "    )\n",
    "\n",
    "(x_data, y_data, z_data), time, single_run = analysis.prepare_data(\"Brustlage\", apply_default_filter=False, plot_alignment=True)\n",
    "\n",
    "single_run = single_run[:, 38000:40000]\n",
    "time = time[38000:40000]\n",
    "\n",
    "analysis.butterfly_plot(single_run, time, 48, f\"Original\")\n",
    "\n",
    "peak_positions, ch, labels, _, _ = analysis.detect_qrs_complex_peaks_cleanest_channel(single_run, print_heart_rate=True, confidence_threshold=0.7)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time, single_run[ch, :], label='Signal', linewidth=1.2)\n",
    "plt.title(f\"QRS Detection - Cleanest Channel {ch + 1}\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if peak_positions is not None and len(peak_positions) > 0:\n",
    "    # window averaging\n",
    "    avg_channels, time_window = analysis.avg_window(single_run, peak_positions, window_left=0.3, window_right=0.5)\n",
    "    analysis.butterfly_plot(avg_channels, time_window, 48, f\"Original\")\n",
    "\n",
    "\n",
    "# Example: Apply LSD plotting to QRS-aligned average data\n",
    "channels_to_plot = list(range(avg_channels.shape[0]))  # or a subset if too many\n",
    "\n",
    "# Create dummy noise_theos (or load actual theoretical noise floor if available)\n",
    "noise_theos = [1.0] * len(channels_to_plot)  # Replace with real values if you have them\n",
    "\n",
    "\n",
    "# Call your function\n",
    "analysis.plot_lsd_multichannel(\n",
    "    data=avg_channels,\n",
    "    noise_theos=noise_theos,\n",
    "    channels=channels_to_plot,\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
